{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oxiZ42B4SwQ-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import T_co\n",
    "# % matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.nn import functional\n",
    "# from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tests import test_prediction, test_generation\n",
    "\n",
    "SEQ_LENGTH = 60\n",
    "\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x5znxQhLSwRC"
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)  # [[int,...],...]\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)  # [[int,...],...]\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')  # [str,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "class LanguageModelSet(Dataset):\n",
    "\n",
    "    def __init__(self, data_loaded):\n",
    "        super().__init__()\n",
    "        data = torch.from_numpy(np.concatenate(data_loaded))\n",
    "\n",
    "        self.len = (data.shape[0] - 1) // SEQ_LENGTH\n",
    "\n",
    "        self.input = torch.zeros((self.len, SEQ_LENGTH), dtype=torch.long)\n",
    "        self.target = torch.zeros_like(self.input)\n",
    "\n",
    "        for i in range(self.len):\n",
    "            self.input[i] = data[i * SEQ_LENGTH:(i + 1) * SEQ_LENGTH]\n",
    "            self.target[i] = data[i * SEQ_LENGTH + 1:(i + 1) * SEQ_LENGTH + 1]\n",
    "\n",
    "    def __getitem__(self, index) -> T_co:\n",
    "        return self.input[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# data loader\n",
    "\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        super(LanguageModelDataLoader, self).__init__(LanguageModelSet(dataset), batch_size, shuffle)\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     # concatenate your articles and build into batches\n",
    "    #\n",
    "    #     raise NotImplemented\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zt-7YsTYSwRI"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class LockedDropOut(nn.Module):\n",
    "    def __init__(self, p, batch_dim=0):\n",
    "        super().__init__()\n",
    "        self.keep = 1 - p\n",
    "        self.batch_dim = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (B,T,C)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            return x\n",
    "        if self.batch_dim == 0:\n",
    "            mask = torch.zeros((1, x.shape[1], x.shape[2]), requires_grad=False, device=x.device).bernoulli_(self.keep)\n",
    "        else:\n",
    "            mask = torch.zeros((x.shape[0], 1, x.shape[2]), requires_grad=False, device=x.device).bernoulli_(self.keep)\n",
    "\n",
    "        mask /= self.keep\n",
    "        mask = mask.expand_as(x)\n",
    "        return mask * x\n",
    "\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, 400)\n",
    "\n",
    "        self.d0 = LockedDropOut(0.65)\n",
    "        self.r1 = nn.LSTM(input_size=400, hidden_size=1150, num_layers=1, batch_first=True)\n",
    "        self.d1 = LockedDropOut(0.3)\n",
    "        self.r2 = nn.LSTM(1150, 1150, batch_first=True)\n",
    "        self.d2 = LockedDropOut(0.3)\n",
    "        self.r3 = nn.LSTM(1150, 400, batch_first=True)\n",
    "        self.d3 = LockedDropOut(0.4)\n",
    "\n",
    "        self.linear = nn.Linear(400, vocab_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -1 / np.sqrt(1150), 1 / np.sqrt(1150))\n",
    "\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
    "        # x: (B,SEQ)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.r1(self.d0(x))[0]\n",
    "        x = self.r2(self.d1(x))[0]\n",
    "        x = self.r3(self.d2(x))[0]\n",
    "        x = self.d3(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return torch.transpose(x, 1, 2)  # B, ENCODING, SEQ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model = model.cuda()\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "\n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), 1, momentum=0.9)\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()  # set to training mode\n",
    "        epoch_loss = 0\n",
    "        batch_num = 0\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "              % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\"\n",
    "            TODO: Define code for training a single batch of inputs\n",
    "\n",
    "        \"\"\"\n",
    "        output = self.model(inputs.to(device))\n",
    "        # print(output.shape)\n",
    "        # print(targets.shape)\n",
    "        loss = self.criterion(output, targets.to(device))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval()  # set to eval mode\n",
    "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model)  # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10,\n",
    "                                                        self.model)  # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "\n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "\n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model)  # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "\n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "              % (self.epochs + 1, self.max_epochs, nll))\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        # don't change these\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "                   model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)),\n",
    "                self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)),\n",
    "                self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)),\n",
    "                self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)),\n",
    "                self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xPI7_kZRSwRN"
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    @staticmethod\n",
    "    def prediction(inp, model):\n",
    "        \"\"\"\n",
    "            TODO: write prediction code here\n",
    "\n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "\n",
    "        inp = torch.from_numpy(inp)\n",
    "        inp = inp.to(device)\n",
    "\n",
    "        return model(inp).cpu().detach().numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def generation(inp, forward, model):\n",
    "        \"\"\"\n",
    "            TODO: write generation code here\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "        \"\"\"\n",
    "\n",
    "        inp = torch.from_numpy(inp)\n",
    "        inp = inp.to(device)\n",
    "\n",
    "        result = torch.zeros((inp.shape[0], forward), device=inp.device, dtype=torch.long)\n",
    "\n",
    "        # res = model(inp)[:, :, -1]\n",
    "        # print(res.shape)\n",
    "\n",
    "        result[:, 0] = torch.argmax(model(inp)[:, :, -1], 1)\n",
    "        for i in range(1, forward):\n",
    "            result[:, i] = torch.argmax(model(torch.unsqueeze(result[:, i - 1], 1))[:, :, -1], 1)\n",
    "\n",
    "        return result.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TiUrjbEjSwRQ"
   },
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "\n",
    "NUM_EPOCHS = 6\n",
    "BATCH_SIZE = 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2HCVG5YISwRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1618812260\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DbHH6zXTSwRa"
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(vocab))\n",
    "\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7D8wTJkBSwRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [2/6]   Loss: 8.7498\n",
      "[VAL]  Epoch [2/6]   Loss: 7.5962\n",
      "Saving model, predictions and generated output for epoch 0 with NLL: 7.5961714\n",
      "[TRAIN]  Epoch [3/6]   Loss: 7.7199\n",
      "[VAL]  Epoch [3/6]   Loss: 7.2800\n",
      "Saving model, predictions and generated output for epoch 1 with NLL: 7.28\n",
      "[TRAIN]  Epoch [4/6]   Loss: 7.5571\n",
      "[VAL]  Epoch [4/6]   Loss: 7.1266\n",
      "Saving model, predictions and generated output for epoch 2 with NLL: 7.126577\n",
      "[TRAIN]  Epoch [5/6]   Loss: 7.4656\n",
      "[VAL]  Epoch [5/6]   Loss: 7.0382\n",
      "Saving model, predictions and generated output for epoch 3 with NLL: 7.0381713\n",
      "[TRAIN]  Epoch [6/6]   Loss: 7.4058\n",
      "[VAL]  Epoch [6/6]   Loss: 6.9656\n",
      "Saving model, predictions and generated output for epoch 4 with NLL: 6.9655747\n",
      "[TRAIN]  Epoch [7/6]   Loss: 7.3636\n",
      "[VAL]  Epoch [7/6]   Loss: 6.9226\n",
      "Saving model, predictions and generated output for epoch 5 with NLL: 6.9226217\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \" + str(epoch) + \" with NLL: \" + str(best_nll))\n",
    "        trainer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "z2FmDqBCSwRf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ipdbmqaGSwRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input | Output #0: while the group was en route , but only three were ultimately able to attack . None of them were | the the the the the the the the the the\n",
      "Input | Output #1: <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United | the the the the the the the the the the\n",
      "Input | Output #2: 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth | the the the the the the the the the the\n",
      "Input | Output #3: , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> , | the the the the the the the the the the\n",
      "Input | Output #4: Warrior were examples of this type . Because their armor was so heavy , they could only carry a single | the the the the the the the the the the\n",
      "Input | Output #5: the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador | the the the the the the the the the the\n",
      "Input | Output #6: <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore | the the the the the the the the the the\n",
      "Input | Output #7: The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation | the the the the the the the the the the\n",
      "Input | Output #8: by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to | the the the the the the the the the the\n",
      "Input | Output #9: Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line | the the the the the the the the the the\n",
      "Input | Output #10: = <eol> = = = French VIII . Corps ( Corps <unk> ) = = = <eol> On 6 November | the the the the the the the the the the\n",
      "Input | Output #11: of the World from 9th Avenue \" . This is regarded as his most famous work . It is considered | the the the the the the the the the the\n",
      "Input | Output #12: — <unk> @-@ 10 , <unk> @-@ 12 , <unk> @-@ 16 , <unk> @-@ 17 — were all converted | the the the the the the the the the the\n",
      "Input | Output #13: And now he has . \" <eol> = = Family = = <eol> <unk> lived 37 of his years in | the the the the the the the the the the\n",
      "Input | Output #14: Hell to which he has been condemned for <unk> . Eliot , in a letter to John <unk> dated 27 | the the the the the the the the the the\n",
      "Input | Output #15: Luoyang area , fulfilling his duties in domestic affairs . <eol> In the autumn of <unk> , he met Li | the the the the the the the the the the\n",
      "Input | Output #16: Power said they enjoyed Block Ball and its number of stages , but wondered how its eight <unk> of memory | the the the the the the the the the the\n",
      "Input | Output #17: by Lloyd F. Lonergan . The cameraman was Jacques <unk> . <eol> = = Release and reception = = <eol> | the the the the the the the the the the\n",
      "Input | Output #18: alone , the Austrians lost more than half their reserve artillery park , 6 @,@ 000 ( out of 8 | the the the the the the the the the the\n",
      "Input | Output #19: while attacking a ship at <unk> in the Dutch East Indies ; the loss was compounded by the fact that | the the the the the the the the the the\n",
      "Input | Output #20: first raised in 2007 by the member of parliament ( MP ) for <unk> . The gangsters may have run | the the the the the the the the the the\n",
      "Input | Output #21: Species are also non @-@ spiny <unk> and includes both large trees with stout stems up to 30 metres ( | the the the the the the the the the the\n",
      "Input | Output #22: \" : specific design issues with the building 's energy efficiency included the fact that the largest room in the | the the the the the the the the the the\n",
      "Input | Output #23: were reported to support over 300 @,@ 000 households in the Brazilian state of <unk> in 2005 , and in | the the the the the the the the the the\n",
      "Input | Output #24: port . <unk> in Vietnam also warned for the potential of heavy rainfall due to the dissipating Tropical Depression <unk> | the the the the the the the the the the\n",
      "Input | Output #25: T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression | the the the the the the the the the the\n",
      "Input | Output #26: South Australia hosted the three @-@ game semi @-@ final series against the New South Wales <unk> . Both teams | the the the the the the the the the the\n",
      "Input | Output #27: Perth from contention and secured the last finals spot for the <unk> . <eol> = = = Statistical leaders = | the the the the the the the the the the\n",
      "Input | Output #28: deemed it an \" amazing pop song \" , lauding the group 's falsetto and its \" head @-@ <unk> | the the the the the the the the the the\n",
      "Input | Output #29: , but began patrolling the English Channel after <unk> @-@ 6 pioneered a route past British <unk> nets and mines | the the the the the the the the the the\n",
      "Input | Output #30: production executives to let him direct . He had already discussed the film with <unk> and Cohen , and felt | the the the the the the the the the the\n",
      "Input | Output #31: and Nick <unk> at Studio <unk> in Los Angeles , California , and was released on August 1 , 2006 | the the the the the the the the the the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see generated output\n",
    "print(trainer.generated[-1])  # get last generated output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}