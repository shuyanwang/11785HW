{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "oxiZ42B4SwQ-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import T_co\n",
    "# % matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.nn import functional\n",
    "# from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tests import test_prediction, test_generation\n",
    "\n",
    "SEQ_LENGTH = 60\n",
    "\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "x5znxQhLSwRC"
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)  # [[int,...],...]\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)  # [[int,...],...]\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')  # [str,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "class LanguageModelSet(Dataset):\n",
    "\n",
    "    def __init__(self, data_loaded):\n",
    "        super().__init__()\n",
    "        data = torch.from_numpy(np.concatenate(data_loaded))\n",
    "\n",
    "        self.len = (data.shape[0] - 1) // SEQ_LENGTH\n",
    "\n",
    "        self.input = torch.zeros((self.len, SEQ_LENGTH), dtype=torch.long)\n",
    "        self.target = torch.zeros_like(self.input)\n",
    "\n",
    "        for i in range(self.len):\n",
    "            self.input[i] = data[i * SEQ_LENGTH:(i + 1) * SEQ_LENGTH]\n",
    "            self.target[i] = data[i * SEQ_LENGTH + 1:(i + 1) * SEQ_LENGTH + 1]\n",
    "\n",
    "    def __getitem__(self, index) -> T_co:\n",
    "        return self.input[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# data loader\n",
    "\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        super(LanguageModelDataLoader, self).__init__(LanguageModelSet(dataset), batch_size, shuffle)\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     # concatenate your articles and build into batches\n",
    "    #\n",
    "    #     raise NotImplemented\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "Zt-7YsTYSwRI"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class LockedDropOut(nn.Module):\n",
    "    def __init__(self, p, batch_dim=0):\n",
    "        super().__init__()\n",
    "        self.keep = 1 - p\n",
    "        self.batch_dim = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (B,T,C)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            return x\n",
    "        if self.batch_dim == 0:\n",
    "            mask = torch.zeros((1, x.shape[1], x.shape[2]), requires_grad=False, device=x.device).bernoulli_(self.keep)\n",
    "        else:\n",
    "            mask = torch.zeros((x.shape[0], 1, x.shape[2]), requires_grad=False, device=x.device).bernoulli_(self.keep)\n",
    "\n",
    "        mask /= self.keep\n",
    "        mask = mask.expand_as(x)\n",
    "        return mask * x\n",
    "\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, 400)\n",
    "\n",
    "        self.d0 = LockedDropOut(0.65)\n",
    "        self.r1 = nn.LSTM(input_size=400, hidden_size=1150, num_layers=1, batch_first=True)\n",
    "        self.d1 = LockedDropOut(0.3)\n",
    "        self.r2 = nn.LSTM(1150, 1150, batch_first=True)\n",
    "        self.d2 = LockedDropOut(0.3)\n",
    "        self.r3 = nn.LSTM(1150, 400, batch_first=True)\n",
    "        self.d3 = LockedDropOut(0.4)\n",
    "\n",
    "        self.linear = nn.Linear(400, vocab_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -1 / np.sqrt(1150), 1 / np.sqrt(1150))\n",
    "\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
    "        # x: (B,SEQ)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.r1(self.d0(x))[0]\n",
    "        x = self.r2(self.d1(x))[0]\n",
    "        x = self.r3(self.d2(x))[0]\n",
    "        x = self.d3(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return torch.transpose(x, 1, 2)  # B, ENCODING, SEQ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model = model.cuda()\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "\n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), 30)\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()  # set to training mode\n",
    "        epoch_loss = 0\n",
    "        batch_num = 0\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "              % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\"\n",
    "            TODO: Define code for training a single batch of inputs\n",
    "\n",
    "        \"\"\"\n",
    "        output = self.model(inputs.to(device))\n",
    "        # print(output.shape)\n",
    "        # print(targets.shape)\n",
    "        loss = self.criterion(output, targets.to(device))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval()  # set to eval mode\n",
    "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model)  # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10,\n",
    "                                                        self.model)  # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "\n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "\n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model)  # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "\n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "              % (self.epochs + 1, self.max_epochs, nll))\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        # don't change these\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "                   model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)),\n",
    "                self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)),\n",
    "                self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)),\n",
    "                self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)),\n",
    "                self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "xPI7_kZRSwRN"
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    @staticmethod\n",
    "    def prediction(inp, model):\n",
    "        \"\"\"\n",
    "            TODO: write prediction code here\n",
    "\n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "\n",
    "        inp = torch.from_numpy(inp)\n",
    "        inp = inp.to(device)\n",
    "\n",
    "        return model(inp)\n",
    "\n",
    "    @staticmethod\n",
    "    def generation(inp, forward, model):\n",
    "        \"\"\"\n",
    "            TODO: write generation code here\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "        \"\"\"\n",
    "\n",
    "        inp = torch.from_numpy(inp)\n",
    "        inp = inp.to(device)\n",
    "\n",
    "        result = torch.zeros((inp.shape[0], forward), device=inp.device, dtype=torch.long)\n",
    "\n",
    "        # res = model(inp)[:, :, -1]\n",
    "        # print(res.shape)\n",
    "\n",
    "        result[:, 0] = torch.argmax(model(inp)[:, :, -1], 1)\n",
    "        for i in range(1, forward):\n",
    "            result[:, i] = torch.argmax(model(torch.unsqueeze(result[:, i - 1], 2))[:, :, -1], 1)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "TiUrjbEjSwRQ"
   },
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "\n",
    "NUM_EPOCHS = 6\n",
    "BATCH_SIZE = 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "2HCVG5YISwRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1618811876\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "DbHH6zXTSwRa"
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(vocab))\n",
    "\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7D8wTJkBSwRc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_nll = 1e30\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \" + str(epoch) + \" with NLL: \" + str(best_nll))\n",
    "        trainer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2FmDqBCSwRf",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipdbmqaGSwRh",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# see generated output\n",
    "print(trainer.generated[-1])  # get last generated output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}